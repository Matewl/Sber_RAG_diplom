{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc6240-989c-4ab4-a7d9-8ad289ce44df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np  \n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import torcg\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_params(params):\n",
    "    model = SentenceTransformer('e5_large/', device='cuda:0')\n",
    "    soft_negatives = pickle.load(open(params['SOFT_PATH'], 'rb'))\n",
    "    hard_negatives = pickle.load(open(params['HARD_PATH'], 'rb'))\n",
    "    if params['ALL_DATA']:\n",
    "        all_data = hard_negatives + soft_negatives\n",
    "    else:\n",
    "        all_data = hard_negatives\n",
    "    train_data = all_data\n",
    "    random.shuffle(train_data)\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'anchor': [data[0] for data in train_data],\n",
    "        'positive': [data[1] for data in train_data],\n",
    "        'negative': [data[2] for data in train_data],\n",
    "    })\n",
    "    train_loss = losses.TripletLoss(\n",
    "        model=model,\n",
    "        distance_metric=losses.SiameseDistanceMetric.COSINE_DISTANCE,\n",
    "        triplet_margin = params['MARGINE']\n",
    "    )\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    def prepare_batch_for_loss(batch):\n",
    "        anchors, positives, negatives = batch['anchor'], batch['positive'], batch['negative']\n",
    "        features = []\n",
    "        for texts in [anchors, positives, negatives]:\n",
    "            tokenized = model.tokenize(texts)\n",
    "            tokenized = {key: value.to(model.device) for key, value in tokenized.items()}\n",
    "            features.append({'input_ids': tokenized['input_ids'], 'attention_mask': tokenized['attention_mask']})\n",
    "        return features\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    num_epochs = params.get('NUM_EPOCHS', 1)\n",
    "    log_interval = 10\n",
    "\n",
    "    data_perfix = params['HARD_PATH'].split('/')[-1].split('.')[0]\n",
    "    model_save_path = f'./finetuned_model_{data_perfix}_{params['MARGINE']}_{params['ALL_DATA']}'\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    epochs_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        cur_losses = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            loss_value = train_loss(prepare_batch_for_loss(batch), None)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            current_loss = loss_value.item()\n",
    "            del loss_value\n",
    "            cur_losses.append(current_loss)\n",
    "            if step % log_interval == log_interval - 1:\n",
    "                clear_output()\n",
    "                print('at_epoch:', epoch, '\\nat_step:', step, '/', len(train_dataloader), '\\nloss:', current_loss)\n",
    "                epochs_losses.append(np.mean(current_loss))\n",
    "                cur_losses = []\n",
    "                plt.plot(epochs_losses)  \n",
    "                plt.show()\n",
    "        model_save_path = f'./finetuned_model_{data_perfix}_{params['MARGINE']}_{params['ALL_DATA']}/epoch_{epoch}'     \n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        model.save(model_save_path)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    \"SOFT_PATH\": 'data/soft_negatives_single_83_001_1_75.pkl',\n",
    "    \"HARD_PATH\": 'data/hard_negatives_single_83_001_1_75.pkl',\n",
    "    \"ALL_DATA\": True,\n",
    "    \"MARGINE\": 0.3,\n",
    "    \"NUM_EPOCHS\": 1\n",
    "},{\n",
    "    \"SOFT_PATH\": 'data/soft_negatives_single_83_001_1_75.pkl',\n",
    "    \"HARD_PATH\": 'data/hard_negatives_single_83_001_1_75.pkl',\n",
    "    \"ALL_DATA\": False,\n",
    "    \"MARGINE\": 0.3,\n",
    "    \"NUM_EPOCHS\": 1\n",
    "},{\n",
    "    \"SOFT_PATH\": 'data/soft_negatives_single_83_001_1_75.pkl',\n",
    "    \"HARD_PATH\": 'data/hard_negatives_single_83_001_1_75.pkl',\n",
    "    \"ALL_DATA\": True,\n",
    "    \"MARGINE\": 0.7,\n",
    "    \"NUM_EPOCHS\": 1\n",
    "},{\n",
    "    \"SOFT_PATH\": 'data/soft_negatives_single_83_001_1_75.pkl',\n",
    "    \"HARD_PATH\": 'data/hard_negatives_single_83_001_1_75.pkl',\n",
    "    \"ALL_DATA\": False,\n",
    "    \"MARGINE\": 0.7,\n",
    "    \"NUM_EPOCHS\": 1\n",
    "},{\n",
    "    \"SOFT_PATH\": 'data/soft_negatives_single_83_001_1_75.pkl',\n",
    "    \"HARD_PATH\": 'data/hard_negatives_single_83_001_1_75.pkl',\n",
    "    \"ALL_DATA\": True,\n",
    "    \"MARGINE\": 0.9,\n",
    "    \"NUM_EPOCHS\": 1\n",
    "},{\n",
    "    \"SOFT_PATH\": 'data/soft_negatives_single_83_001_1_75.pkl',\n",
    "    \"HARD_PATH\": 'data/hard_negatives_single_83_001_1_75.pkl',\n",
    "    \"ALL_DATA\": False,\n",
    "    \"MARGINE\": 0.9,\n",
    "    \"NUM_EPOCHS\": 1\n",
    "}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
