{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cadab3b-45a5-4488-b430-b581738d9b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:50:49.185000Z",
     "iopub.status.busy": "2025-06-09T17:50:49.184731Z",
     "iopub.status.idle": "2025-06-09T17:50:53.303272Z",
     "shell.execute_reply": "2025-06-09T17:50:53.302703Z",
     "shell.execute_reply.started": "2025-06-09T17:50:49.184983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30197667-58f1-4aa1-9640-680c31cc3df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:50:53.304395Z",
     "iopub.status.busy": "2025-06-09T17:50:53.304046Z",
     "iopub.status.idle": "2025-06-09T17:50:54.425774Z",
     "shell.execute_reply": "2025-06-09T17:50:54.425200Z",
     "shell.execute_reply.started": "2025-06-09T17:50:53.304367Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "soft_negatives = pickle.load(open('soft_negatives.pkl', 'rb'))\n",
    "hard_negatives = pickle.load(open('hard_negatives.pkl', 'rb'))\n",
    "all_data = soft_negatives + hard_negatives\n",
    "\n",
    "train_samples = [\n",
    "    InputExample(texts=[triplet[0], triplet[1]], label=1)\n",
    "    for triplet in all_data\n",
    "] + [\n",
    "    InputExample(texts=[triplet[0], triplet[2]], label=1)\n",
    "    for triplet in all_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6845dcf-48c0-47a5-aa62-632a0ef6f41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f50a90-95c5-41f9-a21a-a113e941caac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.losses import MultipleNegativesRankingLoss, BinaryCrossEntropyLoss\n",
    "\n",
    "model = CrossEncoder(\"../models_weights/cross-encoder-russian-msmarco\", num_labels=1).to('cuda:1')\n",
    "\n",
    "# loss = MultipleNegativesRankingLoss(model)\n",
    "loss = BinaryCrossEntropyLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8a5c6-35ca-4b13-bbdb-cf47062b9b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import BatchSamplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195defd-84c7-4b90-b48f-80e77e4376c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainingArguments\n",
    "\n",
    "args = CrossEncoderTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/reranker-MiniLM-msmarco-v2\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"reranker-MiniLM-msmarco-v2\",  # Will be used in W&B if `wandb` is installed\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc7c4d-e7f8-4c7a-9ece-69ab24088f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoderTrainer\n",
    "# 6. Create the trainer & start training\n",
    "trainer = CrossEncoderTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    loss=loss\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "model.save('./cross_encoder_tuned_v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3d9f2-468b-4bbe-b66b-68bfd5021b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:54:27.135623Z",
     "iopub.status.busy": "2025-05-09T14:54:27.135109Z",
     "iopub.status.idle": "2025-05-09T14:54:27.558368Z",
     "shell.execute_reply": "2025-05-09T14:54:27.557839Z",
     "shell.execute_reply.started": "2025-05-09T14:54:27.135608Z"
    },
    "tags": []
   },
   "source": [
    "cross_encoder_name = './cross_encoder_tuned'\n",
    "cross_encoder_model = CrossEncoder(cross_encoder_name, num_labels=1).to('cuda')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
